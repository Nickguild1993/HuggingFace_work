{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/9B0NYkcYWpzSkaA+xlT0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nickguild1993/HuggingFace_work/blob/main/Unit_1_lesson_4_BIAS_N_LIMITATIONS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pretrained models (or even afine-tuned version in production) while powerful, come with limitations.\n",
        "\n",
        "the biggest issue is that because the models must be pretrained on a massive amount of data, researchers scrape all they content they can find, which will include the best and worst of what is available on the internet.\n",
        "\n",
        "(I assume that given the scope of the pretraining, it's incredibly difficult to differentate the \"good\" from the \"bad\" in the pretraining phase)\n",
        "\n",
        "* As an illustration, let's use the example of *fill-mask pipeline with the BERT model:"
      ],
      "metadata": {
        "id": "qjjICja8nGG_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1XZtUvym61k",
        "outputId": "b849aefd-0663-49ae-fab5-78306056b8ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['carpenter', 'lawyer', 'farmer', 'businessman', 'doctor']\n",
            "['nurse', 'maid', 'teacher', 'waitress', 'prostitute']\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "unmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
        "result = unmasker(\"This man works as a [MASK].\")\n",
        "print([r[\"token_str\"] for r in result])\n",
        "\n",
        "result = unmasker(\"This woman works as a [MASK].\")\n",
        "print([r[\"token_str\"] for r in result])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "results for MALE [carpenter, lawyer, farmer, businessman, doctor]\n",
        "\n",
        "results for Female [nurse, waitress, teacher, maid, prostitute]\n",
        "\n",
        "Clearly the output is affected by the gender chosen in the sequence input.\n",
        "\n",
        "* this occurs even though BERT is one of the rare transformer models NOT built by scraping data from all over the internet, but using SUPPOSED neutral data (english wikipedia and bookcorpus datasets)\n",
        "\n",
        "so it's important to consider that your results could easily generate bad shit like racist, sexist, or homophobic content.\n",
        "\n",
        "* fine-tuning your model **WILL NOT** make this INTRINSIC bias disappear."
      ],
      "metadata": {
        "id": "A9PL6w0Sot3T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yD43t-z9nGMh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VafQjmDhnGPt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oHpwNx6EnGSk"
      }
    }
  ]
}