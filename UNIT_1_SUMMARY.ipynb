{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPxcMK8j5Y6xst7HxfueTp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nickguild1993/HuggingFace_work/blob/main/UNIT_1_SUMMARY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### UNIT 1 SUMMARY\n",
        "\n",
        "https://huggingface.co/learn/nlp-course/chapter1/9?fw=pt"
      ],
      "metadata": {
        "id": "LC6nfucIp06x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this chapter, I learned how to approach different NLP tasks using the high level *pipeline()* function from the hugging face transformers.\n",
        "\n",
        "Learned how to search for and use the models in the Hub, as well as how to use the interface API to test the models directly in my browser.\n",
        "\n",
        "Learned how transformer models work on a high level, and about the importance of transfer learning and fine-tuning.\n",
        "\n",
        "* key aspect: I can use the full architecture or only the encoder OR decoder, depdning on the task."
      ],
      "metadata": {
        "id": "Et7VJGnPp4JA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL                              EXAMPLES              TASKS\n",
        "\n",
        "---\n",
        "encoder : ALBERT, DistillBERT, ELECTRA, RoBERTa : sentence classification, NER, extrative question answering\n",
        "\n",
        "decoder : CTRL, GPT, GPT-2, Transformer XL : Text generation\n",
        "\n",
        "encoder-decoder: BART, T5, Marian, mBART : Summarization, translation, generative question answering\n"
      ],
      "metadata": {
        "id": "wNDF_-rwqZrP"
      }
    }
  ]
}